{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import random\n",
        "\n",
        "# Base phrases that are gonna be used for data generation\n",
        "base_phrases = {\n",
        "    'book_flight': [\n",
        "        \"book a flight\", \"I need to book a flight\", \"reserve a flight ticket\", \"I want to fly\",\n",
        "        \"schedule a flight for me\", \"can I get a flight\", \"arrange a flight\", \"need a flight booked\"\n",
        "    ],\n",
        "    'cancel_flight': [\n",
        "        \"cancel my flight\", \"I need to cancel my booking\", \"please cancel my flight reservation\",\n",
        "        \"abort my flight reservation\", \"I have to cancel my flight\", \"stop my flight booking\"\n",
        "    ],\n",
        "    'query_flight': [\n",
        "        \"show me available flights\", \"I want to see flight options\", \"what flights are available\",\n",
        "        \"need information on flights\", \"flight availability\", \"find flights for me\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Generating variations\n",
        "def generate_variations(phrases, num_variations=20):\n",
        "    variations = []\n",
        "    for phrase in phrases:\n",
        "        for _ in range(num_variations):\n",
        "            # All different kinds of data augmentation\n",
        "            variation = phrase\n",
        "            if random.choice([True, False]):\n",
        "                variation = \"please \" + variation\n",
        "            if random.choice([True, False]):\n",
        "                variation = variation + \" now\"\n",
        "            if random.choice([True, False]):\n",
        "                variation = \"Can you \" + variation\n",
        "            if random.choice([True, False]):\n",
        "                variation = variation.replace(\"I\", \"Could I\")\n",
        "            variations.append(variation)\n",
        "    return variations\n",
        "\n",
        "# Generating dataset\n",
        "dataset = []\n",
        "for category, phrases in base_phrases.items():\n",
        "    variations = generate_variations(phrases)\n",
        "    for v in variations:\n",
        "        dataset.append((v, category))\n",
        "\n",
        "random.shuffle(dataset)\n",
        "\n",
        "# Setting amount of entrys\n",
        "while len(dataset) < 1000:\n",
        "    for category, phrases in base_phrases.items():\n",
        "        variations = generate_variations(phrases, 1)\n",
        "        for v in variations:\n",
        "            dataset.append((v, category))\n",
        "            if len(dataset) >= 1000:\n",
        "                break\n",
        "    if len(dataset) >= 1000:\n",
        "        break\n",
        "\n",
        "# Saving into csv\n",
        "filename = 'flight_booking_dataset.csv'\n",
        "with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Phrase', 'Category'])\n",
        "    for entry in dataset:\n",
        "        writer.writerow(entry)\n",
        "\n",
        "print(f\"Dataset saved as {filename}. Total entries: {len(dataset)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4Qzb1b3-jMt",
        "outputId": "3f906cc9-335b-4cf0-e6ab-f86c1980ca8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset saved as flight_booking_dataset.csv. Total entries: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi9PVasot0Um",
        "outputId": "41fff986-ccc1-4435-a4f6-cd315883382d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.2)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Loading dataset\n",
        "df = pd.read_csv('flight_booking_dataset.csv')\n",
        "\n",
        "# Loading tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Encodeing labels\n",
        "label_dict = {'book_flight': 0, 'cancel_flight': 1, 'query_flight': 2}\n",
        "df['label'] = df['Category'].replace(label_dict)\n",
        "\n",
        "# Spliting dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Phrase'], df['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenizeing and encoding sentences\n",
        "def encode_sentences(tokenizer, sentences, max_length=128):\n",
        "    input_ids, attention_masks = [], []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "            sentence,\n",
        "            add_special_tokens = True,\n",
        "            max_length = max_length,\n",
        "            pad_to_max_length = True,\n",
        "            return_attention_mask = True,\n",
        "            return_tensors = 'tf',\n",
        "        )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = tf.concat(input_ids, 0)\n",
        "    attention_masks = tf.concat(attention_masks, 0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "max_length = 128 # This length should be sufficient for the task\n",
        "train_input_ids, train_attention_masks = encode_sentences(tokenizer, X_train, max_length)\n",
        "test_input_ids, test_attention_masks = encode_sentences(tokenizer, X_test, max_length)\n",
        "\n",
        "# Converting labels to categorical\n",
        "train_labels = to_categorical(y_train, num_classes=3)\n",
        "test_labels = to_categorical(y_test, num_classes=3)\n",
        "# Loading pre-trained BERT model. A bit of an overkill.\n",
        "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
        "\n",
        "# Compiling the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5, epsilon=1e-08)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "\n",
        "# Training the model. We dont need to train it a lot, since bert is very capable on its own.\n",
        "batch_size = 32\n",
        "epochs = 3\n",
        "\n",
        "model.fit(\n",
        "    [train_input_ids, train_attention_masks], train_labels,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=([test_input_ids, test_attention_masks], test_labels)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tvh6KZDAmbE",
        "outputId": "ae54930d-ecbf-4dd5-e801-8eba6b1f5da3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "25/25 [==============================] - 81s 950ms/step - loss: 0.7275 - accuracy: 0.7700 - val_loss: 0.3329 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "25/25 [==============================] - 21s 843ms/step - loss: 0.2204 - accuracy: 1.0000 - val_loss: 0.1020 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "25/25 [==============================] - 23s 916ms/step - loss: 0.0700 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78072dee1780>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Following are mock api functions\n",
        "def book_flight():\n",
        "    return \"Flight booked successfully.\"\n",
        "\n",
        "def cancel_flight():\n",
        "    return \"Flight cancelled successfully.\"\n",
        "\n",
        "def query_flights():\n",
        "    return \"Here are the available flights.\"\n",
        "\n",
        "# There we processing user input\n",
        "def classify_intent(text):\n",
        "    # Tokenizing the user input text\n",
        "    input_ids, attention_mask = encode_sentences(tokenizer, [text])\n",
        "\n",
        "    # Making a prediction\n",
        "    predictions = model.predict([input_ids, attention_mask])\n",
        "\n",
        "    # Getting the probabilities\n",
        "    probabilities = tf.nn.softmax(predictions.logits, axis=-1)\n",
        "\n",
        "    predicted_class = tf.argmax(probabilities, axis=1).numpy()[0]\n",
        "    confidence = tf.reduce_max(probabilities, axis=1).numpy()[0]\n",
        "\n",
        "    return predicted_class, confidence\n",
        "\n",
        "# this function responsible for user talking to model loop. Making it a loop allows user to talk with model continuously\n",
        "def interact_with_model():\n",
        "    CONFIDENCE_THRESHOLD = 0.85  # Controls how sure model must be to ask for clarification\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"How can I assist you with your flight today? (Type 'exit' to quit) \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        # Classifying the intent of the user input and getting the confidence level\n",
        "        intent, confidence = classify_intent(user_input)\n",
        "\n",
        "        # Checking if the confidence is below the threshold\n",
        "        if confidence < CONFIDENCE_THRESHOLD:\n",
        "            print(\"I'm not quite sure what you are asking. Could you provide more details?\")\n",
        "            continue\n",
        "\n",
        "        # Calling the mock API function\n",
        "        if intent == 0:\n",
        "            print(book_flight())\n",
        "        elif intent == 1:\n",
        "            print(cancel_flight())\n",
        "        elif intent == 2:\n",
        "            print(query_flights())\n",
        "        else:\n",
        "            print(\"I'm not sure what you're asking. Could you please clarify?\")\n",
        "\n",
        "# Run the interaction function\n",
        "interact_with_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh6qYjiNyYOk",
        "outputId": "ab6d40b5-d3f6-440d-e563-0d8e1d7974a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How can I assist you with your flight today? (Type 'exit' to quit) what are flight from paris ?\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "I'm not quite sure what you are asking. Could you provide more details?\n",
            "How can I assist you with your flight today? (Type 'exit' to quit) show mw flight frop paris \n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Here are the available flights.\n",
            "How can I assist you with your flight today? (Type 'exit' to quit) exit\n"
          ]
        }
      ]
    }
  ]
}